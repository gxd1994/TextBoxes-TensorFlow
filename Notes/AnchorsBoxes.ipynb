{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test \n",
    "## 1. anchor_boxes\n",
    "## 2. groudtruth encode\n",
    "## 3. bboxes decode(not yet finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.insert(0,'../processing/')\n",
    "sys.path.insert(0,'../')\n",
    "from image_processing2 import *\n",
    "import tf_extended as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.31666666666666665, 0.43333333333333335, 0.55, 0.6666666666666666, 0.7833333333333332, 0.8999999999999999]\n"
     ]
    }
   ],
   "source": [
    "img_shape=(300, 300)\n",
    "num_classes=2\n",
    "feat_layers=['conv_4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'pool6']\n",
    "feat_shapes=[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)]\n",
    "scale_range=[0.20, 0.90]\n",
    "anchor_ratios=[1,2,3,5,7,10]\n",
    "normalizations=[20, -1, -1, -1, -1, -1]\n",
    "prior_scaling=[0.1, 0.1, 0.2, 0.2]\n",
    "\n",
    "step = (scale_range[1] - scale_range[0]) / len(feat_shapes)\n",
    "scales = [scale_range[0] + i * step for i in range(len(feat_shapes)+1)]\n",
    "print scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38, 2, 1)\n",
      "[ 0.02368421  0.01674727  0.01367409  0.0105919   0.00895179  0.0074896 ]\n",
      "(38, 38, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "def textbox_anchor_one_layer(img_shape,\n",
    "                             feat_size,\n",
    "                             ratios,\n",
    "                             scale,\n",
    "                             offset = 0.5,\n",
    "                             dtype=np.float32):\n",
    "    # Follow the papers scheme\n",
    "    # 12 ahchor boxes with out sk' = sqrt(sk * sk+1)\n",
    "    y, x = np.mgrid[0:feat_size[0], 0:feat_size[1]] + 0.5\n",
    "    y = y.astype(dtype) / feat_size[0]\n",
    "    x = x.astype(dtype) / feat_size[1]\n",
    "\n",
    "    x_offset = x\n",
    "    y_offset = y + offset\n",
    "    x_out = np.stack((x, x_offset), -1)\n",
    "    y_out = np.stack((y, y_offset), -1)\n",
    "    y_out = np.expand_dims(y_out, axis=-1)\n",
    "    x_out = np.expand_dims(x_out, axis=-1)\n",
    "\n",
    "    # \n",
    "    num_anchors = 6\n",
    "    h = np.zeros((num_anchors, ), dtype=dtype)\n",
    "    w = np.zeros((num_anchors, ), dtype=dtype)\n",
    "    for i ,r in enumerate(ratios):\n",
    "        h[i] = scale / math.sqrt(r) / feat_size[0]\n",
    "        w[i] = scale * math.sqrt(r) / feat_size[1]\n",
    "    return y_out, x_out, h, w\n",
    "\n",
    "y,x,h,w = textbox_anchor_one_layer((300,300), (38,38),(1,2,3,5,7,10),0.9)\n",
    "print y.shape\n",
    "print h\n",
    "print (y -h).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "(38, 38, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "def textbox_achor_all_layers(img_shape,\n",
    "                           layers_shape,\n",
    "                           anchor_ratios,\n",
    "                           scales,\n",
    "                           offset=0.5,\n",
    "                           dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Compute anchor boxes for all feature layers.\n",
    "    \"\"\"\n",
    "    layers_anchors = []\n",
    "    for i, s in enumerate(layers_shape):\n",
    "        anchor_bboxes = textbox_anchor_one_layer(img_shape, s,\n",
    "                                                 anchor_ratios,\n",
    "                                                 scales[i],\n",
    "                                                 offset=offset, dtype=dtype)\n",
    "        layers_anchors.append(anchor_bboxes)\n",
    "    return layers_anchors\n",
    "\n",
    "layers_anchors = textbox_achor_all_layers((300,300), feat_shapes,anchor_ratios,scales)\n",
    "print len(layers_anchors)\n",
    "print len(layers_anchors[0])\n",
    "print layers_anchors[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =========================================================================== #\n",
    "# TensorFlow implementation of Text Boxes encoding / decoding.\n",
    "# =========================================================================== #\n",
    "\n",
    "def tf_text_bboxes_encode_layer(bboxes,\n",
    "                               anchors_layer,\n",
    "                               matching_threshold=0.5,\n",
    "                               prior_scaling=[0.1, 0.1, 0.2, 0.2],\n",
    "                               dtype=tf.float32):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encode groundtruth labels and bounding boxes using Textbox anchors from\n",
    "    one layer.\n",
    "\n",
    "    Arguments:\n",
    "      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;\n",
    "      anchors_layer: Numpy array with layer anchors;\n",
    "      matching_threshold: Threshold for positive match with groundtruth bboxes;\n",
    "      prior_scaling: Scaling of encoded coordinates.\n",
    "\n",
    "    Return:\n",
    "      (target_localizations, target_scores): Target Tensors.\n",
    "    # thisi is a binary problem, so target_score and tartget_labels are same.\n",
    "    \"\"\"\n",
    "    # Anchors coordinates and volume.\n",
    "\n",
    "    yref, xref, href, wref = anchors_layer\n",
    "    print yref.shape\n",
    "    print href.shape\n",
    "    print bboxes.shape\n",
    "    ymin = yref - href / 2.\n",
    "    xmin = xref - wref / 2.\n",
    "    ymax = yref + href / 2.\n",
    "    xmax = xref + wref / 2. \n",
    "    vol_anchors = (xmax - xmin) * (ymax - ymin)\n",
    "    \n",
    "    # Initialize tensors...\n",
    "    shape = (yref.shape[0], yref.shape[1], yref.shape[2], href.size)\n",
    "    # all follow the shape(feat.size, feat.size, 2, 6)\n",
    "    #feat_labels = tf.zeros(shape, dtype=tf.int64)\n",
    "    feat_scores = tf.zeros(shape, dtype=dtype)\n",
    "\n",
    "    feat_ymin = tf.zeros(shape, dtype=dtype)\n",
    "    feat_xmin = tf.zeros(shape, dtype=dtype)\n",
    "    feat_ymax = tf.ones(shape, dtype=dtype)\n",
    "    feat_xmax = tf.ones(shape, dtype=dtype)\n",
    "\n",
    "    def jaccard_with_anchors(bbox):\n",
    "        \"\"\"\n",
    "        Compute jaccard score between a box and the anchors.\n",
    "        \"\"\"\n",
    "        int_ymin = tf.maximum(ymin, bbox[0])\n",
    "        int_xmin = tf.maximum(xmin, bbox[1])\n",
    "        int_ymax = tf.minimum(ymax, bbox[2])\n",
    "        int_xmax = tf.minimum(xmax, bbox[3])\n",
    "        h = tf.maximum(int_ymax - int_ymin, 0.)\n",
    "        w = tf.maximum(int_xmax - int_xmin, 0.)\n",
    "        # Volumes.\n",
    "        inter_vol = h * w\n",
    "        union_vol = vol_anchors - inter_vol \\\n",
    "            + (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        jaccard = tf.div(inter_vol, union_vol)\n",
    "        return jaccard\n",
    "    \n",
    "    \"\"\"\n",
    "    # never use in Textbox\n",
    "    def intersection_with_anchors(bbox):\n",
    "        '''\n",
    "        Compute intersection between score a box and the anchors.\n",
    "        '''\n",
    "        int_ymin = tf.maximum(ymin, bbox[0])\n",
    "        int_xmin = tf.maximum(xmin, bbox[1])\n",
    "        int_ymax = tf.minimum(ymax, bbox[2])\n",
    "        int_xmax = tf.minimum(xmax, bbox[3])\n",
    "        h = tf.maximum(int_ymax - int_ymin, 0.)\n",
    "        w = tf.maximum(int_xmax - int_xmin, 0.)\n",
    "        inter_vol = h * w\n",
    "        scores = tf.div(inter_vol, vol_anchors)\n",
    "        return scores\n",
    "    \"\"\"\n",
    "    \n",
    "    def condition(i, feat_scores,\n",
    "                  feat_ymin, feat_xmin, feat_ymax, feat_xmax):\n",
    "        \"\"\"Condition: check label index.\n",
    "        \"\"\"\n",
    "        r = tf.less(i, 3)\n",
    "        return r\n",
    "\n",
    "    def body(i, feat_scores,feat_ymin, feat_xmin, feat_ymax, feat_xmax,bbox):\n",
    "        \"\"\"Body: update feature labels, scores and bboxes.\n",
    "        Follow the original SSD paper for that purpose:\n",
    "          - assign values when jaccard > 0.5;\n",
    "          - only update if beat the score of other bboxes.\n",
    "        \"\"\"\n",
    "        # Jaccard score.\n",
    "        #bbox = bboxes[i]\n",
    "        jaccard = jaccard_with_anchors(bbox)\n",
    "        # Mask: check threshold + scores + no annotations + num_classes.\n",
    "        mask = tf.greater(jaccard, feat_scores)\n",
    "        mask = tf.logical_and(mask, tf.greater(jaccard, matching_threshold))\n",
    "        #mask = tf.logical_and(mask, feat_scores > -0.5)\n",
    "        #mask = tf.logical_and(mask, label < num_classes)\n",
    "        imask = tf.cast(mask, tf.int64)\n",
    "        fmask = tf.cast(mask, dtype)\n",
    "        # Update values using mask.\n",
    "        #feat_labels = imask * label + (1 - imask) * feat_labels\n",
    "        feat_scores = tf.where(mask, jaccard, feat_scores)\n",
    "\n",
    "        feat_ymin = fmask * bbox[0] + (1 - fmask) * feat_ymin\n",
    "        feat_xmin = fmask * bbox[1] + (1 - fmask) * feat_xmin\n",
    "        feat_ymax = fmask * bbox[2] + (1 - fmask) * feat_ymax\n",
    "        feat_xmax = fmask * bbox[3] + (1 - fmask) * feat_xmax\n",
    "\n",
    "        # Check no annotation label: ignore these anchors...\n",
    "        #interscts = intersection_with_anchors(bbox)\n",
    "        #mask = tf.logical_and(interscts > ignore_threshold,\n",
    "        #                     label == no_annotation_label)\n",
    "        # Replace scores by -1.\n",
    "        #feat_scores = tf.where(mask, -tf.cast(mask, dtype), feat_scores)\n",
    "\n",
    "        return [i+1, feat_scores,\n",
    "                feat_ymin, feat_xmin, feat_ymax, feat_xmax]\n",
    "    # Main loop definition.\n",
    "    '''\n",
    "    i = 0\n",
    "    [i,feat_scores,\n",
    "     feat_ymin, feat_xmin,\n",
    "     feat_ymax, feat_xmax] = tf.while_loop(condition, body,\n",
    "                                           [i, feat_scores,\n",
    "                                            feat_ymin, feat_xmin,\n",
    "                                            feat_ymax, feat_xmax])\n",
    "    '''\n",
    "    for i, bbox in enumerate(tf.unstack(bboxes, axis=0)):\n",
    "        [i,feat_scores,feat_ymin, \n",
    "        feat_xmin, feat_ymax, feat_xmax] = body(i, feat_scores,\n",
    "                                                feat_ymin, feat_xmin, \n",
    "                                                feat_ymax, feat_xmax,bbox)\n",
    "    # Transform to center / size.\n",
    "    feat_cy = (feat_ymax + feat_ymin) / 2.\n",
    "    feat_cx = (feat_xmax + feat_xmin) / 2.\n",
    "    feat_h = feat_ymax - feat_ymin\n",
    "    feat_w = feat_xmax - feat_xmin\n",
    "    # Encode features.\n",
    "    feat_cy = (feat_cy - yref) / href / prior_scaling[0]\n",
    "    feat_cx = (feat_cx - xref) / wref / prior_scaling[1]\n",
    "    feat_h = tf.log(feat_h / href) / prior_scaling[2]\n",
    "    feat_w = tf.log(feat_w / wref) / prior_scaling[3]\n",
    "    # Use SSD ordering: x / y / w / h instead of ours.\n",
    "    feat_localizations = tf.stack([feat_cx, feat_cy, feat_w, feat_h], axis=-1)\n",
    "    return feat_localizations, feat_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_text_bboxes_encode(bboxes,\n",
    "                         anchors,\n",
    "                         matching_threshold=0.5,\n",
    "                         prior_scaling=[0.1, 0.1, 0.2, 0.2],\n",
    "                         dtype=tf.float32,\n",
    "                         scope='ssd_bboxes_encode'):\n",
    "    \"\"\"Encode groundtruth labels and bounding boxes using SSD net anchors.\n",
    "    Encoding boxes for all feature layers.\n",
    "\n",
    "    Arguments:\n",
    "      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;\n",
    "      anchors: List of Numpy array with layer anchors;\n",
    "      matching_threshold: Threshold for positive match with groundtruth bboxes;\n",
    "      prior_scaling: Scaling of encoded coordinates.\n",
    "\n",
    "    Return:\n",
    "      (target_labels, target_localizations, target_scores):\n",
    "        Each element is a list of target Tensors.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(scope):\n",
    "        target_labels = []\n",
    "        target_localizations = []\n",
    "        target_scores = []\n",
    "        for i, anchors_layer in enumerate(anchors):\n",
    "            with tf.name_scope('bboxes_encode_block_%i' % i):\n",
    "                t_loc, t_scores = \\\n",
    "                    tf_text_bboxes_encode_layer(bboxes, anchors_layer,\n",
    "                                                matching_threshold,\n",
    "                                               prior_scaling, dtype)\n",
    "                target_localizations.append(t_loc)\n",
    "                target_scores.append(t_scores)\n",
    "        return target_localizations, target_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name SparseTensor(indices=Tensor(\"ParseSingleExample_1/Slice_Indices_image/name:0\", shape=(?, 1), dtype=int64), values=Tensor(\"ParseSingleExample_1/ParseExample/ParseExample:6\", shape=(?,), dtype=string), dense_shape=Tensor(\"ParseSingleExample_1/Squeeze_Shape_image/name:0\", shape=(1,), dtype=int64))\n",
      "image after decode Tensor(\"decode_jpeg_1/convert_image:0\", shape=(?, ?, 3), dtype=float32)\n",
      "labels: Tensor(\"ExpandDims_11:0\", shape=(1, ?), dtype=int64) \n",
      "(38, 38, 2, 1)\n",
      "(6,)\n",
      "(?, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot infer num from shape (?, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4968af59bf0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m image,label,bboxes = image_processing(image_buffer, bboxes,label,\n\u001b[1;32m      8\u001b[0m                                      train= True, thread_id = 0)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mflocalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_text_bboxes_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers_anchors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatching_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#print flocalization.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print fscores.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c48699524f49>\u001b[0m in \u001b[0;36mtf_text_bboxes_encode\u001b[0;34m(bboxes, anchors, matching_threshold, prior_scaling, dtype, scope)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 t_loc, t_scores =                     tf_text_bboxes_encode_layer(bboxes, anchors_layer,\n\u001b[1;32m     27\u001b[0m                                                 \u001b[0mmatching_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                                prior_scaling, dtype)\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mtarget_localizations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mtarget_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-de2668f60d9b>\u001b[0m in \u001b[0;36mtf_text_bboxes_encode_layer\u001b[0;34m(bboxes, anchors_layer, matching_threshold, prior_scaling, dtype)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                             feat_ymax, feat_xmax])\n\u001b[1;32m    131\u001b[0m     '''\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         [i,feat_scores,feat_ymin, \n\u001b[1;32m    134\u001b[0m         \u001b[0mfeat_xmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_ymax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_xmax\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/python/anaconda/envs/tensorflow2.7/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36munstack\u001b[0;34m(value, num, axis, name)\u001b[0m\n\u001b[1;32m    958\u001b[0m       \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot infer num from shape %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot infer num from shape (?, 4)"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/xiaodiu/Documents/github/projecttextbox/TextBoxes-TensorFlow/data/sythtext/'\n",
    "file_name = data_dir + '1.tfrecord'\n",
    "## test if file_name exists  \n",
    "\n",
    "example = tf.python_io.tf_record_iterator(file_name).next()\n",
    "image_buffer, label, bboxes, name= parse_example(example)\n",
    "image,label,bboxes = image_processing(image_buffer, bboxes,label,\n",
    "                                     train= True, thread_id = 0)\n",
    "flocalization, fscores = tf_text_bboxes_encode(bboxes,layers_anchors,matching_threshold=0.1)\n",
    "#print flocalization.shape\n",
    "#print fscores.shape\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    Image, label, bboxes = sess.run([image, label, bboxes])\n",
    "    flocalization, fscores = sess.run([flocalization,fscores])\n",
    "    print label.shape\n",
    "    print bboxes\n",
    "    #print name\n",
    "    #print width\n",
    "    #print height\n",
    "    print Image.shape\n",
    "    print flocalization[0].shape\n",
    "    for i in range(6):\n",
    "        print np.where(fscores[i] > 0)\n",
    "    \"\"\"\n",
    "    visualize_bbox(Image, bboxes)\n",
    "    skio.imshow(Image)\n",
    "    skio.show()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf_2.7",
   "language": "python",
   "name": "tensorflow2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
